{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Analytics and Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import anderson\n",
    "\n",
    "rain = np.load('rain.npy')\n",
    "rain = .1 * rain\n",
    "rain[rain < 0] = .05/2\n",
    "print(\"Rain mean\", rain.mean())\n",
    "print(\"Rain variance\", rain.var())\n",
    "print(\"Anderson rain\", anderson(rain))\n",
    "\n",
    "scaled = preprocessing.scale(rain)\n",
    "print(\"Scaled mean\", scaled.mean())\n",
    "print(\"Scaled variance\", scaled.var())\n",
    "print(\"Anderson scaled\", anderson(scaled))\n",
    "\n",
    "binarized = preprocessing.binarize(rain.reshape(-1,1))\n",
    "print(np.unique(binarized), binarized.sum())\n",
    "\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(rain.astype(int))\n",
    "print(lb.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "def classify(x, y):\n",
    "    clf = LogisticRegression(random_state=12)\n",
    "    scores = []\n",
    "    kf = KFold(n_splits=10)\n",
    "    for train,test in kf.split(x):\n",
    "      clf.fit(x[train], y[train])\n",
    "      scores.append(clf.score(x[test], y[test]))\n",
    "\n",
    "    print(\"Accuracy: \",np.mean(scores))\n",
    "\n",
    "rain = np.load('rain.npy')\n",
    "dates = np.load('doy.npy')\n",
    "\n",
    "x = np.vstack((dates[:-1], rain[:-1]))\n",
    "y = np.sign(rain[1:])\n",
    "classify(x.T, y)\n",
    "\n",
    "#iris example\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data[:, :2]\n",
    "y = iris.target\n",
    "classify(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from pprint import PrettyPrinter\n",
    "\n",
    "def classify(x, y):\n",
    "    clf = GridSearchCV(SVC(random_state=42, max_iter=100), {'kernel': ['linear', 'poly', 'rbf'], 'C':[1, 10]})\n",
    "    clf.fit(x, y)\n",
    "    print(\"Accuracy: \", clf.score(x, y))\n",
    "    PrettyPrinter().pprint(clf.cv_results_)\n",
    "\n",
    "rain = np.load('rain.npy')\n",
    "dates = np.load('doy.npy')\n",
    "\n",
    "x = np.vstack((dates[:-1], rain[:-1]))\n",
    "y = np.sign(rain[1:])\n",
    "\n",
    "classify(x.T, y)\n",
    "\n",
    "#iris example\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data[:, :2]\n",
    "y = iris.target\n",
    "classify(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def regress(x, y, title):\n",
    "    clf = ElasticNetCV(max_iter=200, cv=10, l1_ratio = [.1, .5, \n",
    ".7, .9, .95, .99, 1])\n",
    "\n",
    "    clf.fit(x, y)\n",
    "    print(\"Score\", clf.score(x, y))\n",
    "\n",
    "    pred = clf.predict(x)\n",
    "    plt.title(\"Scatter plot of prediction and \" + title)\n",
    "    plt.xlabel(\"Prediction\")\n",
    "    plt.ylabel(\"Target\")\n",
    "    plt.scatter(y, pred)\n",
    "    # Show perfect fit line\n",
    "    if \"Boston\" in title:\n",
    "        plt.plot(y, y, label=\"Perfect Fit\")\n",
    "        plt.legend()\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "rain = .1 * np.load('rain.npy')\n",
    "rain[rain < 0] = .05/2\n",
    "dates = np.load('doy.npy')\n",
    "\n",
    "x = np.vstack((dates[:-1], rain[:-1]))\n",
    "y = rain[1:]\n",
    "regress(x.T, y, \"rain data\")\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "x = boston.data\n",
    "y = boston.target\n",
    "regress(x, y, \"Boston house prices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import preprocessing\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def regress(x, y, ncpus, title):\n",
    "    X = preprocessing.scale(x)\n",
    "    Y = preprocessing.scale(y)\n",
    "    clf = SVR(max_iter=ncpus * 200)\n",
    "\n",
    "    train_sizes, train_scores, test_scores = learning_curve(clf, X, Y, n_jobs=ncpus) \n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.plot(train_sizes, train_scores.mean(axis=1), label=\"Train score\")\n",
    "    plt.plot(train_sizes, test_scores.mean(axis=1), '--', label=\"Test score\")\n",
    "    print(\"Max test score \" + title, test_scores.max())\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "rain = .1 * np.load('rain.npy')\n",
    "rain[rain < 0] = .05/2\n",
    "dates = np.load('doy.npy')\n",
    "\n",
    "x = np.vstack((dates[:-1], rain[:-1]))\n",
    "y = rain[1:]\n",
    "ncpus = multiprocessing.cpu_count()\n",
    "regress(x.T, y, ncpus, \"Rain\")\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "x = boston.data\n",
    "y = boston.target\n",
    "regress(x, y, ncpus, \"Boston\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Clustering with affinity propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import cluster\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import euclidean_distances\n",
    "\n",
    "x, _ = datasets.make_blobs(n_samples=100, centers=3, n_features=2, \n",
    "random_state=10)\n",
    "S = euclidean_distances(x)\n",
    "\n",
    "aff_pro = cluster.AffinityPropagation().fit(S)\n",
    "labels = aff_pro.labels_\n",
    "\n",
    "styles = ['o', 'x', '^']\n",
    "\n",
    "for style, label in zip(styles, np.unique(labels)):\n",
    "   print(label)\n",
    "   plt.plot(x[labels == label], style, label=label)\n",
    "plt.title(\"Clustering Blobs\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Mean Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import cluster\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "rain = .1 * np.load('rain.npy')\n",
    "rain[rain < 0] = .05/2\n",
    "dates = np.load('doy.npy')\n",
    "x = np.vstack((dates, rain))\n",
    "df = pd.DataFrame.from_records(x.T, columns=['dates', 'rain'])\n",
    "df = df.groupby('dates').mean()\n",
    "df.plot()\n",
    "x = np.vstack((np.arange(1, len(df) + 1) , \n",
    "df.as_matrix().ravel()))\n",
    "x = x.T\n",
    "ms = cluster.MeanShift()\n",
    "ms.fit(x)\n",
    "labels = ms.predict(x)\n",
    "\n",
    "plt.figure()\n",
    "grays = ['0', '0.5', '0.75']\n",
    "\n",
    "for gray, label in zip(grays, np.unique(labels)):\n",
    "    match = labels == label\n",
    "    x0 = x[:, 0]\n",
    "    x1 = x[:, 1]\n",
    "    plt.plot(x0[match], x1[match], lw=label+1, label=label)\n",
    "    plt.fill_between(x0, x1, where=match, color=gray)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Genetic Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import array\n",
    "import random\n",
    "import numpy as np\n",
    "from deap import algorithms\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "from scipy.stats import shapiro\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", array.array, typecode='d', \n",
    "fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_float\", random.random)\n",
    "toolbox.register(\"individual\", tools.initRepeat, \n",
    "creator.Individual, toolbox.attr_float, 200)\n",
    "toolbox.register(\"populate\", tools.initRepeat, list, \n",
    "toolbox.individual)\n",
    "\n",
    "def eval(individual):\n",
    "    return shapiro(individual)[1],\n",
    "\n",
    "toolbox.register(\"evaluate\", eval)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.1)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=4)\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "pop = toolbox.populate(n=400)\n",
    "hof = tools.HallOfFame(1)\n",
    "stats = tools.Statistics(key=lambda ind: ind.fitness.values)\n",
    "stats.register(\"max\", np.max)\n",
    "\n",
    "algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2, ngen=80, \n",
    "stats=stats, halloffame=hof)\n",
    "\n",
    "print(shapiro(hof[0])[1])\n",
    "plt.hist(hof[0])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theanets\n",
    "import multiprocessing\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rain = .1 * np.load('rain.npy')\n",
    "rain[rain < 0] = .05/2\n",
    "dates = np.load('doy.npy')\n",
    "x = np.vstack((dates[:-1], np.sign(rain[:-1])))\n",
    "x = x.T\n",
    "\n",
    "y = np.vstack(np.sign(rain[1:]),)\n",
    "N = int(.9 * len(x))\n",
    "\n",
    "train = [x[:N], y[:N]]\n",
    "valid = [x[N:], y[N:]]\n",
    "\n",
    "net = theanets.Regressor(layers=[2,3,1])\n",
    "\n",
    "net.train(train,valid,learning_rate=0.1,momentum=0.5)\n",
    "\n",
    "pred = net.predict(x[N:]).ravel()\n",
    "print(\"Pred Min\", pred.min(), \"Max\", pred.max())\n",
    "print(\"Y Min\", y.min(), \"Max\", y.max())\n",
    "print(\"Accuracy\", accuracy_score(y[N:], pred >= .5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "import pydotplus as pydot\n",
    "import io\n",
    "import numpy as np\n",
    "from tempfile import NamedTemporaryFile\n",
    "\n",
    "rain = .1 * np.load('rain.npy')\n",
    "rain[rain < 0] = .05/2\n",
    "dates = np.load('doy.npy').astype(int)\n",
    "x = np.vstack((dates[:-1], np.sign(rain[:-1])))\n",
    "x = x.T\n",
    "\n",
    "y = np.sign(rain[1:])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
    "random_state=37)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(random_state=37)\n",
    "params = {\"max_depth\": [2, None],\n",
    "              \"min_samples_leaf\": sp_randint(1, 5),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "rscv = RandomizedSearchCV(clf, params)\n",
    "rscv.fit(x_train,y_train)\n",
    "\n",
    "sio = io.StringIO()\n",
    "tree.export_graphviz(rscv.best_estimator_, out_file=sio, \n",
    "feature_names=['day-of-year','yest'])\n",
    "dec_tree = pydot.graph_from_dot_data(sio.getvalue())\n",
    "\n",
    "with NamedTemporaryFile(prefix='rain', suffix='.png', \n",
    "delete=False) as f:\n",
    "    dec_tree.write_png(f.name)\n",
    "    print(\"Written figure to\", f.name)\n",
    "\n",
    "print(\"Best Train Score\", rscv.best_score_)\n",
    "print(\"Test Score\", rscv.score(x_test, y_test))\n",
    "print(\"Best params\", rscv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
